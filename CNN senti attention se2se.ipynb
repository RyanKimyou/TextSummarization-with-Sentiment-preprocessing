{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Stories 92579\n"
     ]
    }
   ],
   "source": [
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}\n",
    "def clean_text(text, remove_stopwords):\n",
    "    '''Remove unwanted characters, stopwords, and format the text to create fewer nulls word embeddings'''\n",
    "    \n",
    "    # Convert words to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace contractions with their longer forms \n",
    "    if True:\n",
    "        text = text.split()\n",
    "        new_text = []\n",
    "        for word in text:\n",
    "            if word in contractions:\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text)\n",
    "    \n",
    "    # Format words and remove unwanted characters\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    \n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "\n",
    "    return text\n",
    "from pickle import load \n",
    "# load from file\n",
    "stories = load(open('cnn_dataset.pkl', 'rb'))\n",
    "print('Loaded Stories %d' % len(stories))\n",
    "\n",
    "st = []\n",
    "ab = []\n",
    "for i in range(len(stories)):\n",
    "    \n",
    "    a,b = list(stories[i].values())\n",
    "    st.append(a)\n",
    "    ab.append(b)\n",
    "    \n",
    "s = []\n",
    "for i in range(len(st)):\n",
    "    s.append(\", \".join(st[i]))\n",
    "    \n",
    "a = []\n",
    "for i in range(len(st)):\n",
    "    a.append(\", \".join(ab[i]))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_texts[:2]\n",
    "del_s = []\n",
    "for i in range(len(st)-1):    \n",
    "    if len(st[i])<= 3:\n",
    "        del_s.append(st[i])\n",
    "        del st[i]\n",
    "        del ab[i]\n",
    "            #del ab[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92309 92309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(st),len(ab))\n",
    "del_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [[st[i][a] for a in range(2)] for i in range(len(st))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_e = [[st[i][a] for a in range(2,len(st[i]))] for i in range(len(st))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92309"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "x = [word_tokenize(d) for d in lst[0]]\n",
    "len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['its official us president barack obama wants lawmakers to weigh in on whether to use military force in syria',\n",
       " 'obama sent a letter to the heads of the house and senate on saturday night hours after announcing that he believes military action against syrian targets is the right step to take over the alleged use of chemical weapons']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new york city cuba chile',\n",
       " 'transcript',\n",
       " 'this is a rush transcript this copy may not be in its final form and may be updated',\n",
       " 'carl azuz cnn student news anchor old mcdonald had a farm and if you could text about that fast enough you might have won grand today youll meet the teenager who did im carl azuz welcome to cnn student news',\n",
       " 'first up un general assembly',\n",
       " 'azuz first up leaders from around the world are coming together for a meeting in new york city its the united nations general assembly and it gets together every year the group is going to talk about world issues different leaders will make speeches president obama is scheduled to address the assembly today',\n",
       " 'so what why does it matter that a bunch of leaders are having a meeting well the united nations general assembly is made up of countries and when we say theyre talking about world issues we mean big subjects like poverty and security and specific things like the war in afghanistan or irans nuclear program they cant create new laws but the decisions that they make and the policies that they come up with can have a big influence on what goes on in the world',\n",
       " 'health care provisions',\n",
       " 'azuz in the health care reform bill that you see president obama signing over my shoulder here that mightve been his biggest victory of his first two years in office and parts of that law go into effect this week for example you can stay on your parents health insurance until youre and insurance companies cant turn down children with medical conditions that exist at the time they apply for insurance some people were and still are against this law though for one thing it can cost a lot of money plus critics dont like the idea that people have to get health insurance that part of the bill goes into effect in a few years',\n",
       " 'whats the word',\n",
       " 'tomeka jones cnn student news whats the word',\n",
       " 'the sector of a countrys economy that isnt run by its government',\n",
       " 'private sector',\n",
       " 'thats the word',\n",
       " 'cuban economy',\n",
       " 'azuz running a business in the private sector means risks and rewards you can set your own prices but theres no one to really fall back on if things dont go so well shasta darlington looks at whats in store for thousands of cubans who are about to lose their government jobs and make the shift into the private sector',\n",
       " 'begin video',\n",
       " 'shasta darlington cnn correspondent havana a tall order in communist cuba finding jobs for half a million laidoff workers in the private sector here in old havana not everyone is celebrating this capitalist notion like it or not employees at this barbershop around the corner are being pushed off the state payroll and handed the shop theyll be able to set prices and keep earnings but theyll now have to pay taxes and rent and theres no longer the guarantee of a fixed income',\n",
       " 'gerardo havana barber translated ive been working for the state for years now and im not interested in going private says gerardo i want to keep working for the state',\n",
       " 'darlington cuba plans to shed ten percent of public sector jobs over the next six months and allow more private enterprise to absorb the unemployed a dramatic attempt by president raul castro to reshape the sputtering economy he says the state simply cant afford a bloated and unproductive workforce but dont expect americanstyle big business cubas new entrepreneurs will be encouraged to start small operations maybe driving taxis laying bricks or perhaps repairing toys now to get an idea of whats in store for them were talking to some of the people already working in the countrys miniscule private sector',\n",
       " 'emilio mendoza was laid off during cubas last major economic crisis in the he bought a government license and set up a cobblers shop in his driveway he says cubans should see this as an opportunity isidro a taxi driver says it depends on how much the state charges its new entrepreneurs in taxes and licensing fees they all agree the days of getting paid by the government whether you work or lounge about are over',\n",
       " 'still the state controls about percent of the economy these modest proposals arent likely to radically shift that balance but they will give life to a new class of small businesses that could change the face of cuba',\n",
       " 'end video',\n",
       " 'shoutout',\n",
       " 'stan case cnn student news time for the shoutout which one of these is the flag of chile if you think you know it shout it out is it a b c or d youve got three seconds go option c is chiles flag its design was influenced by the us flag thats your answer and thats your shoutout',\n",
       " 'hours in the chilean mine',\n",
       " 'azuz the men who are waiting to be rescued from a mine in chile are experiencing things most people never will and most people hope they never will take something as simple as time we can check our watches our cell phones they can do that too but when we look outside we can see the sun we can see the moon we can sort of estimate what time of day or night it is in some cases they cant do that karl penhaul shows us a day in the life when you are trapped underground',\n",
       " 'begin video',\n",
       " 'karl penhaul cnn correspondent chile a new dawn breaks miners face another day trapped half a mile deep rescue workers say the men never lost their notion of time',\n",
       " 'miguel fortt chile rescue coordinator translated the miners have cell phones so they had a calendar they knew perfectly what day it was and what time it was the only thing they didnt know was what the weather was like',\n",
       " 'penhaul its am on the surface far underground day shift is starting theyre working to help rescue themselves',\n",
       " 'fortt translated they have eight hours of rest another eighthour work shift and eight hours to play games read write letters jog or have a walk because they have access to about km of tunnels',\n",
       " 'penhaul time is marked by meals sent down in metal tubes rescuers call carrier pigeons nurse mabel rios is supervising',\n",
       " 'mabel rios nurse translated about we send them breakfast at am a milkshake at we send them lunch at pm another milkshake and around pm we send them their dinner',\n",
       " 'penhaul first job of the day check air quality by midday paramedic yonni barrios has checked all the miners vital signs and sent the data to doctors above around the clock miners help with the rescue effort clearing debris from the drills now boring an escape shaft at pm day shift ends miners play games listen to music and work out on the orders of a personal trainer far above',\n",
       " 'fortt translated because theyre sitting down all day they have a personal trainer to help them cut down their waistline so they can fit in the rescue capsule',\n",
       " 'penhaul work or rest the miners spend their day wandering up and down between the workshop refuge or camp but until the day one of the drills finally rescues them those lives must stay on hold karl penhaul cnn at the san jose mine in northern chile',\n",
       " 'end video',\n",
       " 'heroes promo',\n",
       " 'azuz the cnn heroes program honors everyday folks who find ways to change the world this years top cnn heroes are being announced today you can go to cnncom to find out who they are and learn about what they do',\n",
       " 'teachers lounge promo',\n",
       " 'azuz and teachers the cnn teachers lounge is open you can find it in the bottom right corner of our front page thats cnnstudentnewscom the teachers lounge is a place for you teachers to sound off on issues in education this week we want to know what advice you have for new teachers',\n",
       " 'texting champion',\n",
       " 'azuz were not sure we have any advice for brianna hendrickson at least not when it comes to texting the year old took first place in the national texting championship the final challenge type out a modified version of old mcdonald brianna nailed it in just seconds the prize she won for texting and the chance to compete again win that one and she might get another grand plus get to pick a charity thatll get a donation',\n",
       " 'before we go',\n",
       " 'azuz thats a lot of dough were cooking up a different ingredient for todays before we go segment corn you probably cant tell from this high up but thats what this is its actually a corn maze the annual idaho attraction is opening up this week the designer says it took him two days he does it all by hand can you imagine spending two straight days out in the fields making this',\n",
       " 'goodbye',\n",
       " 'azuz thats a guy who really gets lost in his work were back tomorrow we hope youll lend us an ear then youll find many kernels of knowledge its gonna be cobs of fun whoo we could do corny puns all day but shucks were out of time']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_e[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success-----\n",
      "Time:  514.9288197981065\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.util import *\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as sia\n",
    "start = timeit.default_timer()\n",
    "import pandas as pd\n",
    "#Your statements here\n",
    "\n",
    "\n",
    "sid=sia()\n",
    "sentiment_com=[]\n",
    "sentiment_pos=[]\n",
    "sentiment_neg=[]\n",
    "sentiment_neu=[]\n",
    "script=[]\n",
    "senti_list=[]\n",
    "for i in range(len(lst_e)):\n",
    "    word_ = lst_e[i]\n",
    "    sentiment_com=[]\n",
    "    sentiment_pos=[]\n",
    "    sentiment_neg=[]\n",
    "    sentiment_neu=[]\n",
    "    script=[]\n",
    "    for word in word_:\n",
    "    #print(word)\n",
    "        ss = sid.polarity_scores(word)\n",
    "        sentiment_com.append(ss['compound'])        \n",
    "        sentiment_pos.append(ss['pos'])\n",
    "        sentiment_neg.append(ss['neg'])\n",
    "        sentiment_neu.append(ss['neu'])\n",
    "        script.append(word)\n",
    "    #print(ss)\n",
    "    #com_len = len(sentiment_com)\n",
    "    #pos_len = len(sentiment_pos)\n",
    "    #neg_len = len(sentiment_neg_\n",
    "    #neu_len = len(sentiment_neu)\n",
    "    #sc_len =len(script)\n",
    "    percentile_list = pd.DataFrame(\n",
    "    {\n",
    "     'sentiment_sc': sentiment_com,\n",
    "     'sentiment_pos': sentiment_pos,\n",
    "     'sentiment_neg': sentiment_neg,\n",
    "     'sentiment_neu': sentiment_neu,\n",
    "     'script': script\n",
    "    })\n",
    "    senti_list.append(percentile_list)\n",
    "    #print(script) \n",
    "    \n",
    "    \n",
    "print(\"success-----\")\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success-----\n",
      "Time:  110.81480546402895\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "scipt_prepro= []\n",
    "#for a in range(len(senti_list)):   \n",
    "for a in range(len(senti_list)):      \n",
    "    aaa= []\n",
    "    for i in range(len(senti_list[a][\"sentiment_sc\"] )-1):\n",
    "        bbb = senti_list[a][\"sentiment_sc\"][i] - senti_list[a][\"sentiment_sc\"][i+1]\n",
    "        aaa.append(abs(bbb))\n",
    "\n",
    "    #print(aaa)\n",
    "\n",
    "                   \n",
    "    abb = max((aaa))\n",
    "    for c in range(len(aaa)):\n",
    "        if abb == aaa[c]:\n",
    "            #print(i)\n",
    "            df_1 = senti_list[a][senti_list[a].index == c]\n",
    "            #print(1)\n",
    "            df_2 = senti_list[a][senti_list[a].index == c+1]\n",
    "            \n",
    "            break\n",
    "\n",
    "    \n",
    "    modDfObj1 = df_1.append(df_2 , ignore_index=True)\n",
    "    scipt_prepro.append(modDfObj1)\n",
    "\n",
    "    \n",
    "print(\"success-----\")\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_=[]\n",
    "for i in range(len(scipt_prepro)):\n",
    "    for a in range(len(scipt_prepro[i][\"script\"])):\n",
    "        lst[i].append(scipt_prepro[i][\"script\"][a])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['its official us president barack obama wants lawmakers to weigh in on whether to use military force in syria',\n",
       " 'obama sent a letter to the heads of the house and senate on saturday night hours after announcing that he believes military action against syrian targets is the right step to take over the alleged use of chemical weapons',\n",
       " 'some global leaders have expressed support but the british parliaments vote against military action earlier this week was a blow to obamas hopes of getting strong backing from key nato allies',\n",
       " 'on saturday obama proposed what he said would be a limited military action against syrian president bashar alassad any military attack would not be openended or include us ground forces he said']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst)\n",
    "lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92309"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asda=[]\n",
    "for i in range(len(lst)):\n",
    "    asda.append([word_tokenize(d) for d in lst[i]])\n",
    "    \n",
    "   \n",
    "dd = []\n",
    "for i in range(len(asda)):\n",
    "    for a in range(len(asda[i])):\n",
    "        dd.append(len(asda[i][a]))\n",
    "        \n",
    "cc = []\n",
    "for b in range(0,369236,4):\n",
    "    cc.append(dd[b]+dd[b+1]+dd[b+2]+dd[b+3])\n",
    "len(cc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#st = []\n",
    "#ab = []\n",
    "'''for i in range(len(stories)):\n",
    "    \n",
    "    a,b = list(stories[i].values())\n",
    "    st.append(a)\n",
    "    ab.append(b)'''\n",
    "    \n",
    "s = []\n",
    "for i in range(len(lst)):\n",
    "    s.append(\", \".join(lst[i]))\n",
    "    \n",
    "a = []\n",
    "for i in range(len(ab)):\n",
    "    a.append(\", \".join(ab[i]))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['its official us president barack obama wants lawmakers to weigh in on whether to use military force in syria',\n",
       " 'obama sent a letter to the heads of the house and senate on saturday night hours after announcing that he believes military action against syrian targets is the right step to take over the alleged use of chemical weapons',\n",
       " 'some global leaders have expressed support but the british parliaments vote against military action earlier this week was a blow to obamas hopes of getting strong backing from key nato allies',\n",
       " 'on saturday obama proposed what he said would be a limited military action against syrian president bashar alassad any military attack would not be openended or include us ground forces he said']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92309 92309\n"
     ]
    }
   ],
   "source": [
    "s[1]\n",
    "print(len(s),len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syrian official obama climbed to the top of the tree doesnt know how to get down, obama sends a letter to the heads of the house and senate, obama to seek congressional approval on military action against syria, aim is to determine whether cw were used not by whom says un spokesman ---------------- its official us president barack obama wants lawmakers to weigh in on whether to use military force in syria, obama sent a letter to the heads of the house and senate on saturday night hours after announcing that he believes military action against syrian targets is the right step to take over the alleged use of chemical weapons, some global leaders have expressed support but the british parliaments vote against military action earlier this week was a blow to obamas hopes of getting strong backing from key nato allies, on saturday obama proposed what he said would be a limited military action against syrian president bashar alassad any military attack would not be openended or include us ground forces he said\n"
     ]
    }
   ],
   "source": [
    "print(a[0],\"----------------\",s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.12.0\n",
      "Summaries are complete.\n",
      "Texts are complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.layers.core import Dense\n",
    "from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "import csv\n",
    "'''#Cell 9:'''\n",
    "clean_summaries = []\n",
    "for summary in a:\n",
    "    clean_summaries.append(clean_text(str(summary), remove_stopwords=False))\n",
    "print(\"Summaries are complete.\")\n",
    "\n",
    "clean_texts = []\n",
    "for text in s:\n",
    "    clean_texts.append(clean_text(str(text), remove_stopwords=True))\n",
    "print(\"Texts are complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92309 92309\n"
     ]
    }
   ],
   "source": [
    "print(len(clean_texts),len(clean_summaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "official us president barack obama wants lawmakers weigh whether use military force syria obama sent letter heads house senate saturday night hours announcing believes military action syrian targets right step take alleged use chemical weapons global leaders expressed support british parliaments vote military action earlier week blow obamas hopes getting strong backing key nato allies saturday obama proposed said would limited military action syrian president bashar alassad military attack would openended include us ground forces said ---------- syrian official obama climbed to the top of the tree doesnt know how to get down  obama sends a letter to the heads of the house and senate  obama to seek congressional approval on military action against syria  aim is to determine whether cw were used not by whom says un spokesman\n"
     ]
    }
   ],
   "source": [
    "print(clean_texts[0],\"----------\",clean_summaries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_texts[:2]\n",
    "a = []\n",
    "for i in range(len(clean_texts)-1):\n",
    "    if len(clean_texts[i])<= 1:\n",
    "            a.append(clean_texts[i])\n",
    "            del clean_texts[i]\n",
    "            del clean_summaries[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92309 92309\n"
     ]
    }
   ],
   "source": [
    "print(len(clean_texts),len(clean_summaries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL DEFINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import collections\n",
    "import pickle\n",
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "\n",
    "#train_article_path = \"sumdata/train/train.article.txt\"\n",
    "#train_title_path = \"sumdata/train/train.title.txt\"\n",
    "#valid_article_path = \"sumdata/train/valid.article.filter.txt\"\n",
    "#valid_title_path = \"sumdata/train/valid.title.filter.txt\"\n",
    "\n",
    "\n",
    "def clean_str(sentence):\n",
    "    sentence = re.sub(\"[#.]+\", \"#\", sentence)\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def get_text_list(a, b, toy):\n",
    "    #with open (data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    if not toy:\n",
    "        return [clean_str(x.strip()) for x in f.readlines()]\n",
    "    else:\n",
    "        return [clean_str(x.strip()) for x in f.readlines()][:80000]\n",
    "\n",
    "\n",
    "def build_dict(step, toy=False):\n",
    "    if step == \"train\":\n",
    "        \n",
    "        #train_article_list = get_text_list(train_article_path, toy)\n",
    "        #train_title_list = get_text_list(train_title_path, toy)\n",
    "        \n",
    "        \n",
    "        words = list()\n",
    "        for sentence in clean_texts[:70000] +clean_summaries[:70000]:\n",
    "            for word in word_tokenize(sentence):\n",
    "                words.append(word)\n",
    "\n",
    "        word_counter = collections.Counter(words).most_common()\n",
    "        word_dict = dict()\n",
    "        word_dict[\"<padding>\"] = 0\n",
    "        word_dict[\"<unk>\"] = 1\n",
    "        word_dict[\"<s>\"] = 2\n",
    "        word_dict[\"</s>\"] = 3\n",
    "        for word, _ in word_counter:\n",
    "            word_dict[word] = len(word_dict)\n",
    "\n",
    "        with open(\"word_dict.pickle\", \"wb\") as f:\n",
    "            pickle.dump(word_dict, f)\n",
    "\n",
    "    elif step == \"valid\":\n",
    "        with open(\"word_dict.pickle\", \"rb\") as f:\n",
    "            word_dict = pickle.load(f)\n",
    "\n",
    "    reversed_dict = dict(zip(word_dict.values(), word_dict.keys()))\n",
    "\n",
    "    article_max_len = 130\n",
    "    summary_max_len = 20\n",
    "\n",
    "    return word_dict, reversed_dict, article_max_len, summary_max_len\n",
    "\n",
    "\n",
    "def build_dataset(step, word_dict, article_max_len, summary_max_len, toy=False):\n",
    "    if step == \"train\":\n",
    "        #article_list = get_text_list(train_article_path, toy)\n",
    "        #title_list = get_text_list(train_title_path, toy)\n",
    "        clean_texts[:70000]\n",
    "        clean_summaries[:70000]\n",
    "    elif step == \"valid\":\n",
    "        article_list = get_text_list(valid_article_path, toy)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    x = [word_tokenize(d) for d in clean_texts[:70000]]\n",
    "    x = [[word_dict.get(w, word_dict[\"<unk>\"]) for w in d] for d in x]\n",
    "    x = [d[:article_max_len] for d in x]\n",
    "    x = [d + (article_max_len - len(d)) * [word_dict[\"<padding>\"]] for d in x]\n",
    "    \n",
    "    if step == \"valid\":\n",
    "        return x\n",
    "    else:        \n",
    "        y = [word_tokenize(d) for d in clean_summaries[:70000]]\n",
    "        y = [[word_dict.get(w, word_dict[\"<unk>\"]) for w in d] for d in y]\n",
    "        y = [d[:(summary_max_len - 1)] for d in y]\n",
    "        return x, y\n",
    "\n",
    "\n",
    "def batch_iter(inputs, outputs, batch_size, num_epochs):\n",
    "    inputs = np.array(inputs)\n",
    "    outputs = np.array(outputs)\n",
    "\n",
    "    num_batches_per_epoch = (len(inputs) - 1) // batch_size + 1\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_num in range(num_batches_per_epoch):\n",
    "            start_index = batch_num * batch_size\n",
    "            end_index = min((batch_num + 1) * batch_size, len(inputs))\n",
    "            yield inputs[start_index:end_index], outputs[start_index:end_index]\n",
    "\n",
    "\n",
    "def get_init_embedding(reversed_dict, embedding_size):\n",
    "    glove_file = \"glove.42B.300d.txt\"\n",
    "    word2vec_file = get_tmpfile(\"word2vec_format.vec\")\n",
    "    glove2word2vec(glove_file, word2vec_file)\n",
    "    print(\"Loading Glove vectors...\")\n",
    "    word_vectors = KeyedVectors.load_word2vec_format(word2vec_file)\n",
    "\n",
    "    word_vec_list = list()\n",
    "    for _, word in sorted(reversed_dict.items()):\n",
    "        try:\n",
    "            word_vec = word_vectors.word_vec(word)\n",
    "        except KeyError:\n",
    "            word_vec = np.zeros([embedding_size], dtype=np.float32)\n",
    "\n",
    "        word_vec_list.append(word_vec)\n",
    "\n",
    "    # Assign random vector to <s>, </s> token\n",
    "    word_vec_list[2] = np.random.normal(0, 1, embedding_size)\n",
    "    word_vec_list[3] = np.random.normal(0, 1, embedding_size)\n",
    "\n",
    "    return np.array(word_vec_list)\n",
    "#tf.get_variable_scope().reuse_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dictionary...\n",
      "Loading training dataset...\n"
     ]
    }
   ],
   "source": [
    "print(\"Building dictionary...\")\n",
    "word_dict, reversed_dict, article_max_len, summary_max_len = build_dict(\"train\", toy=True)\n",
    "print(\"Loading training dataset...\")\n",
    "train_x, train_y = build_dataset(\"train\", word_dict, article_max_len, summary_max_len, toy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144571 70000 70000\n"
     ]
    }
   ],
   "source": [
    "print(len(reversed_dict),len(train_x),len(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "#from utils import get_init_embedding\n",
    "#Namespace(batch_size=128, beam_width=5, embedding_size=300, glove=True, keep_prob=0.8,\n",
    "#learning_rate=0.001, num_epochs=10, num_hidden=150, num_layers=2, toy=False)\n",
    "'''\n",
    "    parser.add_argument(\"--num_hidden\", type=int, default=150, help=\"Network size.\")\n",
    "    parser.add_argument(\"--num_layers\", type=int, default=2, help=\"Network depth.\")\n",
    "    parser.add_argument(\"--beam_width\", type=int, default=10, help=\"Beam width for beam search decoder.\")\n",
    "    parser.add_argument(\"--glove\", action=\"store_true\", help=\"Use glove as initial word embedding.\")\n",
    "    parser.add_argument(\"--embedding_size\", type=int, default=300, help=\"Word embedding size.\")\n",
    "\n",
    "    parser.add_argument(\"--learning_rate\", type=float, default=1e-3, help=\"Learning rate.\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=64, help=\"Batch size.\")\n",
    "    parser.add_argument(\"--num_epochs\", type=int, default=10, help=\"Number of epochs.\")\n",
    "    parser.add_argument(\"--keep_prob\", type=float, default=0.8, help=\"Dropout keep prob.\")\n",
    "\n",
    "    parser.add_argument(\"--toy\", action=\"store_true\", help=\"Use only 50K samples of data\")\n",
    "\n",
    "    parser.add_argument(\"--with_model\", action=\"store_true\", help=\"Continue from previously saved model\")'''\n",
    "class Model(object):\n",
    "    def __init__(self, reversed_dict, article_max_len, summary_max_len, forward_only=False):\n",
    "        \n",
    "        self.vocabulary_size = len(reversed_dict)\n",
    "        self.embedding_size = 300\n",
    "        self.num_hidden = 150\n",
    "        self.num_layers = 2\n",
    "        self.learning_rate = 0.001\n",
    "        self.beam_width = 5\n",
    "        if not forward_only:\n",
    "            self.keep_prob = 0.8\n",
    "        else:\n",
    "            self.keep_prob = 1.0\n",
    "        self.cell = tf.nn.rnn_cell.BasicLSTMCell\n",
    "        with tf.variable_scope(\"decoder/projection\"):\n",
    "            self.projection_layer = tf.layers.Dense(self.vocabulary_size, use_bias=False)\n",
    "\n",
    "        self.batch_size = tf.placeholder(tf.int32, (), name=\"batch_size\")\n",
    "        self.X = tf.placeholder(tf.int32, [None, article_max_len])\n",
    "        self.X_len = tf.placeholder(tf.int32, [None])\n",
    "        self.decoder_input = tf.placeholder(tf.int32, [None, summary_max_len])\n",
    "        self.decoder_len = tf.placeholder(tf.int32, [None])\n",
    "        self.decoder_target = tf.placeholder(tf.int32, [None, summary_max_len])\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "        with tf.name_scope(\"embedding\"):\n",
    "            if not forward_only :\n",
    "                init_embeddings = tf.constant(get_init_embedding(reversed_dict, self.embedding_size), dtype=tf.float32)\n",
    "            else:\n",
    "                init_embeddings = tf.random_uniform([self.vocabulary_size, self.embedding_size], -1.0, 1.0)\n",
    "            #tf.get_variable_scope().reuse_variables()\n",
    "            self.embeddings = tf.get_variable(\"embeddings\", initializer=init_embeddings)             \n",
    "            self.encoder_emb_inp = tf.transpose(tf.nn.embedding_lookup(self.embeddings, self.X), perm=[1, 0, 2])\n",
    "            self.decoder_emb_inp = tf.transpose(tf.nn.embedding_lookup(self.embeddings, self.decoder_input), perm=[1, 0, 2])\n",
    "\n",
    "        with tf.name_scope(\"encoder\"):\n",
    "            fw_cells = [self.cell(self.num_hidden) for _ in range(self.num_layers)]\n",
    "            bw_cells = [self.cell(self.num_hidden) for _ in range(self.num_layers)]\n",
    "            fw_cells = [rnn.DropoutWrapper(cell) for cell in fw_cells]\n",
    "            bw_cells = [rnn.DropoutWrapper(cell) for cell in bw_cells]\n",
    "\n",
    "            encoder_outputs, encoder_state_fw, encoder_state_bw = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(\n",
    "                fw_cells, bw_cells, self.encoder_emb_inp,\n",
    "                sequence_length=self.X_len, time_major=True, dtype=tf.float32)\n",
    "            self.encoder_output = tf.concat(encoder_outputs, 2)\n",
    "            encoder_state_c = tf.concat((encoder_state_fw[0].c, encoder_state_bw[0].c), 1)\n",
    "            encoder_state_h = tf.concat((encoder_state_fw[0].h, encoder_state_bw[0].h), 1)\n",
    "            self.encoder_state = rnn.LSTMStateTuple(c=encoder_state_c, h=encoder_state_h)\n",
    "\n",
    "        with tf.name_scope(\"decoder\"), tf.variable_scope(\"decoder\") as decoder_scope:\n",
    "            decoder_cell = self.cell(self.num_hidden * 2)\n",
    "\n",
    "            if not forward_only:\n",
    "                attention_states = tf.transpose(self.encoder_output, [1, 0, 2])\n",
    "                attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n",
    "                    self.num_hidden * 2, attention_states, memory_sequence_length=self.X_len, normalize=True)\n",
    "                decoder_cell = tf.contrib.seq2seq.AttentionWrapper(decoder_cell, attention_mechanism,\n",
    "                                                                   attention_layer_size=self.num_hidden * 2)\n",
    "                initial_state = decoder_cell.zero_state(dtype=tf.float32, batch_size=self.batch_size)\n",
    "                initial_state = initial_state.clone(cell_state=self.encoder_state)\n",
    "                helper = tf.contrib.seq2seq.TrainingHelper(self.decoder_emb_inp, self.decoder_len, time_major=True)\n",
    "                decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, helper, initial_state)\n",
    "                outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, output_time_major=True, scope=decoder_scope)\n",
    "                self.decoder_output = outputs.rnn_output\n",
    "                self.logits = tf.transpose(\n",
    "                    self.projection_layer(self.decoder_output), perm=[1, 0, 2])\n",
    "                self.logits_reshape = tf.concat(\n",
    "                    [self.logits, tf.zeros([self.batch_size, summary_max_len - tf.shape(self.logits)[1], self.vocabulary_size])], axis=1)\n",
    "            else:\n",
    "                tiled_encoder_output = tf.contrib.seq2seq.tile_batch(\n",
    "                    tf.transpose(self.encoder_output, perm=[1, 0, 2]), multiplier=self.beam_width)\n",
    "                tiled_encoder_final_state = tf.contrib.seq2seq.tile_batch(self.encoder_state, multiplier=self.beam_width)\n",
    "                tiled_seq_len = tf.contrib.seq2seq.tile_batch(self.X_len, multiplier=self.beam_width)\n",
    "                attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n",
    "                    self.num_hidden * 2, tiled_encoder_output, memory_sequence_length=tiled_seq_len, normalize=True)\n",
    "                decoder_cell = tf.contrib.seq2seq.AttentionWrapper(decoder_cell, attention_mechanism,\n",
    "                                                                   attention_layer_size=self.num_hidden * 2)\n",
    "                initial_state = decoder_cell.zero_state(dtype=tf.float32, batch_size=self.batch_size * self.beam_width)\n",
    "                initial_state = initial_state.clone(cell_state=tiled_encoder_final_state)\n",
    "                decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n",
    "                    cell=decoder_cell,\n",
    "                    embedding=self.embeddings,\n",
    "                    start_tokens=tf.fill([self.batch_size], tf.constant(2)),\n",
    "                    end_token=tf.constant(3),\n",
    "                    initial_state=initial_state,\n",
    "                    beam_width=self.beam_width,\n",
    "                    output_layer=self.projection_layer\n",
    "                )\n",
    "                outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    decoder, output_time_major=True, maximum_iterations=summary_max_len, scope=decoder_scope)\n",
    "                self.prediction = tf.transpose(outputs.predicted_ids, perm=[1, 2, 0])\n",
    "\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            if not forward_only:\n",
    "                crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                    logits=self.logits_reshape, labels=self.decoder_target)\n",
    "                weights = tf.sequence_mask(self.decoder_len, summary_max_len, dtype=tf.float32)\n",
    "                self.loss = tf.reduce_sum(crossent * weights / tf.to_float(self.batch_size))\n",
    "\n",
    "                params = tf.trainable_variables()\n",
    "                gradients = tf.gradients(self.loss, params)\n",
    "                clipped_gradients, _ = tf.clip_by_global_norm(gradients, 5.0)\n",
    "                optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "                self.update = optimizer.apply_gradients(zip(clipped_gradients, params), global_step=self.global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove vectors...\n",
      "WARNING:tensorflow:From <ipython-input-31-202f5fa98a77>:57: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "\n",
      "Iteration starts.\n",
      "Number of batches per epoch : 1094\n",
      "step 1000: loss = 124.84038543701172\n",
      " Epoch 1: Model is saved. Elapsed: 00:15:49.65 \n",
      "\n",
      "step 2000: loss = 111.39311218261719\n",
      " Epoch 2: Model is saved. Elapsed: 00:23:09.34 \n",
      "\n",
      "step 3000: loss = 112.24323272705078\n",
      " Epoch 3: Model is saved. Elapsed: 00:30:28.35 \n",
      "\n",
      "step 4000: loss = 88.24851989746094\n",
      " Epoch 4: Model is saved. Elapsed: 00:37:47.98 \n",
      "\n",
      "step 5000: loss = 85.29522705078125\n",
      " Epoch 5: Model is saved. Elapsed: 00:45:08.51 \n",
      "\n",
      "step 6000: loss = 79.40284729003906\n",
      " Epoch 6: Model is saved. Elapsed: 00:52:27.17 \n",
      "\n",
      "step 7000: loss = 74.144775390625\n",
      " Epoch 7: Model is saved. Elapsed: 00:59:44.84 \n",
      "\n",
      "step 8000: loss = 72.76388549804688\n",
      " Epoch 8: Model is saved. Elapsed: 01:07:02.65 \n",
      "\n",
      "step 9000: loss = 65.515380859375\n",
      " Epoch 9: Model is saved. Elapsed: 01:14:21.02 \n",
      "\n",
      "step 10000: loss = 55.12068176269531\n",
      " Epoch 10: Model is saved. Elapsed: 01:21:43.18 \n",
      "\n",
      "step 11000: loss = 63.40665054321289\n",
      "step 12000: loss = 55.98253631591797\n",
      " Epoch 11: Model is saved. Elapsed: 01:29:01.44 \n",
      "\n",
      "step 13000: loss = 57.36941146850586\n",
      " Epoch 12: Model is saved. Elapsed: 01:36:28.95 \n",
      "\n",
      "step 14000: loss = 46.03908920288086\n",
      " Epoch 13: Model is saved. Elapsed: 01:43:48.30 \n",
      "\n",
      "step 15000: loss = 45.297096252441406\n",
      " Epoch 14: Model is saved. Elapsed: 01:51:05.88 \n",
      "\n",
      "step 16000: loss = 39.62073516845703\n",
      " Epoch 15: Model is saved. Elapsed: 01:58:28.01 \n",
      "\n",
      "step 17000: loss = 34.594322204589844\n",
      " Epoch 16: Model is saved. Elapsed: 02:05:45.12 \n",
      "\n",
      "step 18000: loss = 40.10399627685547\n",
      " Epoch 17: Model is saved. Elapsed: 02:13:02.96 \n",
      "\n",
      "step 19000: loss = 37.83892822265625\n",
      " Epoch 18: Model is saved. Elapsed: 02:20:20.47 \n",
      "\n",
      "step 20000: loss = 36.11662673950195\n",
      " Epoch 19: Model is saved. Elapsed: 02:27:38.30 \n",
      "\n",
      "step 21000: loss = 42.571685791015625\n",
      " Epoch 20: Model is saved. Elapsed: 02:34:56.11 \n",
      "\n",
      "step 22000: loss = 35.32326889038086\n",
      " Epoch 21: Model is saved. Elapsed: 02:42:14.20 \n",
      "\n",
      "step 23000: loss = 21.594301223754883\n",
      "step 24000: loss = 28.20466423034668\n",
      " Epoch 22: Model is saved. Elapsed: 02:49:40.14 \n",
      "\n",
      "step 25000: loss = 26.5080623626709\n",
      " Epoch 23: Model is saved. Elapsed: 02:56:57.46 \n",
      "\n",
      "step 26000: loss = 23.34107208251953\n",
      " Epoch 24: Model is saved. Elapsed: 03:04:18.54 \n",
      "\n",
      "step 27000: loss = 18.829483032226562\n",
      " Epoch 25: Model is saved. Elapsed: 03:11:36.88 \n",
      "\n",
      "step 28000: loss = 17.847938537597656\n",
      " Epoch 26: Model is saved. Elapsed: 03:19:02.98 \n",
      "\n",
      "step 29000: loss = 20.29921531677246\n",
      " Epoch 27: Model is saved. Elapsed: 03:26:21.07 \n",
      "\n",
      "step 30000: loss = 20.03316879272461\n",
      " Epoch 28: Model is saved. Elapsed: 03:33:40.36 \n",
      "\n",
      "step 31000: loss = 16.842044830322266\n",
      " Epoch 29: Model is saved. Elapsed: 03:41:00.11 \n",
      "\n",
      "step 32000: loss = 17.51679801940918\n",
      " Epoch 30: Model is saved. Elapsed: 03:48:17.96 \n",
      "\n",
      "step 33000: loss = 19.744417190551758\n",
      " Epoch 31: Model is saved. Elapsed: 03:55:35.78 \n",
      "\n",
      "step 34000: loss = 17.407901763916016\n",
      "step 35000: loss = 10.958429336547852\n",
      " Epoch 32: Model is saved. Elapsed: 04:02:58.78 \n",
      "\n",
      "step 36000: loss = 13.998351097106934\n",
      " Epoch 33: Model is saved. Elapsed: 04:10:16.67 \n",
      "\n",
      "step 37000: loss = 16.992341995239258\n",
      " Epoch 34: Model is saved. Elapsed: 04:17:35.37 \n",
      "\n",
      "step 38000: loss = 12.903505325317383\n",
      " Epoch 35: Model is saved. Elapsed: 04:24:52.90 \n",
      "\n",
      "step 39000: loss = 10.247185707092285\n",
      " Epoch 36: Model is saved. Elapsed: 04:32:10.51 \n",
      "\n",
      "step 40000: loss = 15.88364028930664\n",
      " Epoch 37: Model is saved. Elapsed: 04:39:29.21 \n",
      "\n",
      "step 41000: loss = 9.524911880493164\n",
      " Epoch 38: Model is saved. Elapsed: 04:46:46.89 \n",
      "\n",
      "step 42000: loss = 10.173093795776367\n",
      " Epoch 39: Model is saved. Elapsed: 04:54:06.50 \n",
      "\n",
      "step 43000: loss = 11.165912628173828\n",
      " Epoch 40: Model is saved. Elapsed: 05:01:26.51 \n",
      "\n",
      "step 44000: loss = 7.545772552490234\n",
      " Epoch 41: Model is saved. Elapsed: 05:08:45.77 \n",
      "\n",
      "step 45000: loss = 7.739082336425781\n",
      " Epoch 42: Model is saved. Elapsed: 05:16:09.85 \n",
      "\n",
      "step 46000: loss = 7.536351203918457\n",
      "step 47000: loss = 10.318835258483887\n",
      " Epoch 43: Model is saved. Elapsed: 05:23:29.33 \n",
      "\n",
      "step 48000: loss = 6.16422176361084\n",
      " Epoch 44: Model is saved. Elapsed: 05:30:49.67 \n",
      "\n",
      "step 49000: loss = 5.951701641082764\n",
      " Epoch 45: Model is saved. Elapsed: 05:38:09.83 \n",
      "\n",
      "step 50000: loss = 8.332693099975586\n",
      " Epoch 46: Model is saved. Elapsed: 05:45:29.65 \n",
      "\n",
      "step 51000: loss = 6.960854530334473\n",
      " Epoch 47: Model is saved. Elapsed: 05:52:48.16 \n",
      "\n",
      "step 52000: loss = 9.787565231323242\n",
      " Epoch 48: Model is saved. Elapsed: 06:00:10.29 \n",
      "\n",
      "step 53000: loss = 6.900600910186768\n",
      " Epoch 49: Model is saved. Elapsed: 06:07:28.23 \n",
      "\n",
      "step 54000: loss = 6.212977409362793\n",
      " Epoch 50: Model is saved. Elapsed: 06:14:46.33 \n",
      "\n",
      "step 55000: loss = 8.69753646850586\n",
      " Epoch 51: Model is saved. Elapsed: 06:22:04.76 \n",
      "\n",
      "step 56000: loss = 6.324185848236084\n",
      " Epoch 52: Model is saved. Elapsed: 06:29:26.48 \n",
      "\n",
      "step 57000: loss = 5.72107458114624\n",
      " Epoch 53: Model is saved. Elapsed: 06:36:45.28 \n",
      "\n",
      "step 58000: loss = 6.149882793426514\n",
      "step 59000: loss = 5.087860107421875\n",
      " Epoch 54: Model is saved. Elapsed: 06:44:10.35 \n",
      "\n",
      "step 60000: loss = 6.257272720336914\n",
      " Epoch 55: Model is saved. Elapsed: 06:51:29.02 \n",
      "\n",
      "step 61000: loss = 6.325592994689941\n",
      " Epoch 56: Model is saved. Elapsed: 06:58:47.65 \n",
      "\n",
      "step 62000: loss = 4.599679470062256\n",
      " Epoch 57: Model is saved. Elapsed: 07:06:06.26 \n",
      "\n",
      "step 63000: loss = 4.789529323577881\n",
      " Epoch 58: Model is saved. Elapsed: 07:13:26.69 \n",
      "\n",
      "step 64000: loss = 5.304783344268799\n",
      " Epoch 59: Model is saved. Elapsed: 07:20:45.24 \n",
      "\n",
      "step 65000: loss = 7.022454261779785\n",
      " Epoch 60: Model is saved. Elapsed: 07:28:04.12 \n",
      "\n",
      "step 66000: loss = 5.064499378204346\n",
      " Epoch 61: Model is saved. Elapsed: 07:35:22.71 \n",
      "\n",
      "step 67000: loss = 4.877649307250977\n",
      " Epoch 62: Model is saved. Elapsed: 07:42:42.69 \n",
      "\n",
      "step 68000: loss = 4.733818531036377\n",
      " Epoch 63: Model is saved. Elapsed: 07:50:02.78 \n",
      "\n",
      "step 69000: loss = 4.025388240814209\n",
      "step 70000: loss = 4.997511863708496\n",
      " Epoch 64: Model is saved. Elapsed: 07:57:24.12 \n",
      "\n",
      "step 71000: loss = 3.8479421138763428\n",
      " Epoch 65: Model is saved. Elapsed: 08:04:47.73 \n",
      "\n",
      "step 72000: loss = 6.27232027053833\n",
      " Epoch 66: Model is saved. Elapsed: 08:12:05.91 \n",
      "\n",
      "step 73000: loss = 4.491007328033447\n",
      " Epoch 67: Model is saved. Elapsed: 08:19:24.46 \n",
      "\n",
      "step 74000: loss = 3.4682869911193848\n",
      " Epoch 68: Model is saved. Elapsed: 08:26:46.54 \n",
      "\n",
      "step 75000: loss = 3.862426996231079\n",
      " Epoch 69: Model is saved. Elapsed: 08:34:04.31 \n",
      "\n",
      "step 76000: loss = 5.487321853637695\n",
      " Epoch 70: Model is saved. Elapsed: 08:41:23.95 \n",
      "\n",
      "step 77000: loss = 3.591309070587158\n",
      " Epoch 71: Model is saved. Elapsed: 08:48:45.44 \n",
      "\n",
      "step 78000: loss = 5.20837926864624\n",
      " Epoch 72: Model is saved. Elapsed: 08:56:06.27 \n",
      "\n",
      "step 79000: loss = 4.642796039581299\n",
      " Epoch 73: Model is saved. Elapsed: 09:03:33.32 \n",
      "\n",
      "step 80000: loss = 4.056316375732422\n",
      " Epoch 74: Model is saved. Elapsed: 09:10:58.70 \n",
      "\n",
      "step 81000: loss = 4.089468479156494\n",
      "step 82000: loss = 4.092082500457764\n",
      " Epoch 75: Model is saved. Elapsed: 09:18:17.57 \n",
      "\n",
      "step 83000: loss = 4.699634552001953\n",
      " Epoch 76: Model is saved. Elapsed: 09:25:36.50 \n",
      "\n",
      "step 84000: loss = 4.571277141571045\n",
      " Epoch 77: Model is saved. Elapsed: 09:32:58.44 \n",
      "\n",
      "step 85000: loss = 3.126189708709717\n",
      " Epoch 78: Model is saved. Elapsed: 09:40:19.75 \n",
      "\n",
      "step 86000: loss = 3.527440309524536\n",
      " Epoch 79: Model is saved. Elapsed: 09:47:41.91 \n",
      "\n",
      "step 87000: loss = 3.499783754348755\n",
      " Epoch 80: Model is saved. Elapsed: 09:55:01.05 \n",
      "\n",
      "step 88000: loss = 3.2887375354766846\n",
      " Epoch 81: Model is saved. Elapsed: 10:02:20.91 \n",
      "\n",
      "step 89000: loss = 3.8626699447631836\n",
      " Epoch 82: Model is saved. Elapsed: 10:09:40.13 \n",
      "\n",
      "step 90000: loss = 3.2467260360717773\n",
      " Epoch 83: Model is saved. Elapsed: 10:16:58.88 \n",
      "\n",
      "step 91000: loss = 3.669269561767578\n",
      " Epoch 84: Model is saved. Elapsed: 10:24:17.82 \n",
      "\n",
      "step 92000: loss = 3.0825960636138916\n",
      " Epoch 85: Model is saved. Elapsed: 10:31:38.78 \n",
      "\n",
      "step 93000: loss = 3.7812182903289795\n",
      "step 94000: loss = 3.0601425170898438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 86: Model is saved. Elapsed: 10:38:57.53 \n",
      "\n",
      "step 95000: loss = 4.298541069030762\n",
      " Epoch 87: Model is saved. Elapsed: 10:46:15.63 \n",
      "\n",
      "step 96000: loss = 5.1939311027526855\n",
      " Epoch 88: Model is saved. Elapsed: 10:53:41.38 \n",
      "\n",
      "step 97000: loss = 3.772606134414673\n",
      " Epoch 89: Model is saved. Elapsed: 11:01:07.21 \n",
      "\n",
      "step 98000: loss = 3.101750373840332\n",
      " Epoch 90: Model is saved. Elapsed: 11:08:25.79 \n",
      "\n",
      "step 99000: loss = 2.97963285446167\n",
      " Epoch 91: Model is saved. Elapsed: 11:15:44.86 \n",
      "\n",
      "step 100000: loss = 2.640542984008789\n",
      " Epoch 92: Model is saved. Elapsed: 11:23:03.90 \n",
      "\n",
      "step 101000: loss = 5.416953086853027\n",
      " Epoch 93: Model is saved. Elapsed: 11:30:28.52 \n",
      "\n",
      "step 102000: loss = 2.6272130012512207\n",
      " Epoch 94: Model is saved. Elapsed: 11:37:50.66 \n",
      "\n",
      "step 103000: loss = 3.2202935218811035\n",
      " Epoch 95: Model is saved. Elapsed: 11:45:10.30 \n",
      "\n",
      "step 104000: loss = 2.2530627250671387\n",
      "step 105000: loss = 3.1842072010040283\n",
      " Epoch 96: Model is saved. Elapsed: 11:52:31.16 \n",
      "\n",
      "step 106000: loss = 2.535487413406372\n",
      " Epoch 97: Model is saved. Elapsed: 11:59:54.44 \n",
      "\n",
      "step 107000: loss = 3.116046905517578\n",
      " Epoch 98: Model is saved. Elapsed: 12:07:17.30 \n",
      "\n",
      "step 108000: loss = 2.9631292819976807\n",
      " Epoch 99: Model is saved. Elapsed: 12:14:35.77 \n",
      "\n",
      "step 109000: loss = 3.4365792274475098\n",
      " Epoch 100: Model is saved. Elapsed: 12:21:56.83 \n",
      "\n",
      "step 110000: loss = 2.680934429168701\n",
      " Epoch 101: Model is saved. Elapsed: 12:29:16.30 \n",
      "\n",
      "step 111000: loss = 2.373030185699463\n",
      " Epoch 102: Model is saved. Elapsed: 12:36:34.86 \n",
      "\n",
      "step 112000: loss = 4.106072425842285\n",
      " Epoch 103: Model is saved. Elapsed: 12:43:55.24 \n",
      "\n",
      "step 113000: loss = 3.5924391746520996\n",
      " Epoch 104: Model is saved. Elapsed: 12:51:23.00 \n",
      "\n",
      "step 114000: loss = 2.958399534225464\n",
      " Epoch 105: Model is saved. Elapsed: 12:58:42.25 \n",
      "\n",
      "step 115000: loss = 2.71124267578125\n",
      " Epoch 106: Model is saved. Elapsed: 13:06:00.36 \n",
      "\n",
      "step 116000: loss = 2.366413116455078\n",
      "step 117000: loss = 2.9029359817504883\n",
      " Epoch 107: Model is saved. Elapsed: 13:13:18.45 \n",
      "\n",
      "step 118000: loss = 2.946098804473877\n",
      " Epoch 108: Model is saved. Elapsed: 13:20:37.26 \n",
      "\n",
      "step 119000: loss = 2.825265645980835\n",
      " Epoch 109: Model is saved. Elapsed: 13:27:56.83 \n",
      "\n",
      "step 120000: loss = 1.9365003108978271\n",
      " Epoch 110: Model is saved. Elapsed: 13:35:20.10 \n",
      "\n",
      "step 121000: loss = 2.7057297229766846\n",
      " Epoch 111: Model is saved. Elapsed: 13:42:42.85 \n",
      "\n",
      "step 122000: loss = 3.0896859169006348\n",
      " Epoch 112: Model is saved. Elapsed: 13:50:00.66 \n",
      "\n",
      "step 123000: loss = 3.069005250930786\n",
      " Epoch 113: Model is saved. Elapsed: 13:57:19.69 \n",
      "\n",
      "step 124000: loss = 3.0936896800994873\n",
      " Epoch 114: Model is saved. Elapsed: 14:04:41.27 \n",
      "\n",
      "step 125000: loss = 2.396244525909424\n",
      " Epoch 115: Model is saved. Elapsed: 14:12:02.88 \n",
      "\n",
      "step 126000: loss = 2.7275948524475098\n",
      " Epoch 116: Model is saved. Elapsed: 14:19:21.73 \n",
      "\n",
      "step 127000: loss = 2.6282029151916504\n",
      " Epoch 117: Model is saved. Elapsed: 14:26:41.76 \n",
      "\n",
      "step 128000: loss = 3.239582061767578\n",
      "step 129000: loss = 1.8767696619033813\n",
      " Epoch 118: Model is saved. Elapsed: 14:34:10.37 \n",
      "\n",
      "step 130000: loss = 2.5058059692382812\n",
      " Epoch 119: Model is saved. Elapsed: 14:41:28.88 \n",
      "\n",
      "step 131000: loss = 2.415790557861328\n",
      " Epoch 120: Model is saved. Elapsed: 14:48:47.92 \n",
      "\n",
      "step 132000: loss = 2.369800090789795\n",
      " Epoch 121: Model is saved. Elapsed: 14:56:06.50 \n",
      "\n",
      "step 133000: loss = 2.455003261566162\n",
      " Epoch 122: Model is saved. Elapsed: 15:03:27.04 \n",
      "\n",
      "step 134000: loss = 2.9513356685638428\n",
      " Epoch 123: Model is saved. Elapsed: 15:10:46.11 \n",
      "\n",
      "step 135000: loss = 2.9735167026519775\n",
      " Epoch 124: Model is saved. Elapsed: 15:18:05.26 \n",
      "\n",
      "step 136000: loss = 2.767855405807495\n",
      " Epoch 125: Model is saved. Elapsed: 15:25:28.84 \n",
      "\n",
      "step 137000: loss = 2.070376396179199\n",
      " Epoch 126: Model is saved. Elapsed: 15:32:50.22 \n",
      "\n",
      "step 138000: loss = 2.4940149784088135\n",
      " Epoch 127: Model is saved. Elapsed: 15:40:10.09 \n",
      "\n",
      "step 139000: loss = 3.0560081005096436\n",
      "step 140000: loss = 2.4650309085845947\n",
      " Epoch 128: Model is saved. Elapsed: 15:47:28.66 \n",
      "\n",
      "step 141000: loss = 3.714456081390381\n",
      " Epoch 129: Model is saved. Elapsed: 15:54:47.54 \n",
      "\n",
      "step 142000: loss = 2.629430055618286\n",
      " Epoch 130: Model is saved. Elapsed: 16:02:06.15 \n",
      "\n",
      "step 143000: loss = 2.455281972885132\n",
      " Epoch 131: Model is saved. Elapsed: 16:09:24.50 \n",
      "\n",
      "step 144000: loss = 2.8907546997070312\n",
      " Epoch 132: Model is saved. Elapsed: 16:16:43.37 \n",
      "\n",
      "step 145000: loss = 1.594146728515625\n",
      " Epoch 133: Model is saved. Elapsed: 16:24:02.02 \n",
      "\n",
      "step 146000: loss = 2.1597094535827637\n",
      " Epoch 134: Model is saved. Elapsed: 16:31:21.47 \n",
      "\n",
      "step 147000: loss = 2.6906700134277344\n",
      " Epoch 135: Model is saved. Elapsed: 16:38:40.36 \n",
      "\n",
      "step 148000: loss = 2.5511856079101562\n",
      " Epoch 136: Model is saved. Elapsed: 16:46:02.00 \n",
      "\n",
      "step 149000: loss = 2.092794418334961\n",
      " Epoch 137: Model is saved. Elapsed: 16:53:20.71 \n",
      "\n",
      "step 150000: loss = 2.176614284515381\n",
      " Epoch 138: Model is saved. Elapsed: 17:00:40.68 \n",
      "\n",
      "step 151000: loss = 2.380636692047119\n",
      "step 152000: loss = 2.017669677734375\n",
      " Epoch 139: Model is saved. Elapsed: 17:08:01.95 \n",
      "\n",
      "step 153000: loss = 2.572467088699341\n",
      " Epoch 140: Model is saved. Elapsed: 17:15:21.38 \n",
      "\n",
      "step 154000: loss = 2.1237263679504395\n",
      " Epoch 141: Model is saved. Elapsed: 17:22:45.03 \n",
      "\n",
      "step 155000: loss = 2.149461030960083\n",
      " Epoch 142: Model is saved. Elapsed: 17:30:03.73 \n",
      "\n",
      "step 156000: loss = 2.4887735843658447\n",
      " Epoch 143: Model is saved. Elapsed: 17:37:22.41 \n",
      "\n",
      "step 157000: loss = 2.07707142829895\n",
      " Epoch 144: Model is saved. Elapsed: 17:44:42.74 \n",
      "\n",
      "step 158000: loss = 2.369687080383301\n",
      " Epoch 145: Model is saved. Elapsed: 17:52:01.49 \n",
      "\n",
      "step 159000: loss = 2.159111499786377\n",
      " Epoch 146: Model is saved. Elapsed: 17:59:24.37 \n",
      "\n",
      "step 160000: loss = 3.034510612487793\n",
      " Epoch 147: Model is saved. Elapsed: 18:06:43.13 \n",
      "\n",
      "step 161000: loss = 1.3668125867843628\n",
      " Epoch 148: Model is saved. Elapsed: 18:14:02.07 \n",
      "\n",
      "step 162000: loss = 1.9002333879470825\n",
      "step 163000: loss = 2.649913787841797\n",
      " Epoch 149: Model is saved. Elapsed: 18:21:19.92 \n",
      "\n",
      "step 164000: loss = 1.829665184020996\n",
      " Epoch 150: Model is saved. Elapsed: 18:28:39.18 \n",
      "\n",
      "step 165000: loss = 2.5790762901306152\n",
      " Epoch 151: Model is saved. Elapsed: 18:35:58.44 \n",
      "\n",
      "step 166000: loss = 2.588594913482666\n",
      " Epoch 152: Model is saved. Elapsed: 18:43:17.26 \n",
      "\n",
      "step 167000: loss = 2.286318302154541\n",
      " Epoch 153: Model is saved. Elapsed: 18:50:42.13 \n",
      "\n",
      "step 168000: loss = 2.5840744972229004\n",
      " Epoch 154: Model is saved. Elapsed: 18:58:00.97 \n",
      "\n",
      "step 169000: loss = 3.0840725898742676\n",
      " Epoch 155: Model is saved. Elapsed: 19:05:23.09 \n",
      "\n",
      "step 170000: loss = 1.7831881046295166\n",
      " Epoch 156: Model is saved. Elapsed: 19:12:42.29 \n",
      "\n",
      "step 171000: loss = 3.166883945465088\n",
      " Epoch 157: Model is saved. Elapsed: 19:20:01.78 \n",
      "\n",
      "step 172000: loss = 2.1179161071777344\n",
      " Epoch 158: Model is saved. Elapsed: 19:27:21.37 \n",
      "\n",
      "step 173000: loss = 3.174314260482788\n",
      " Epoch 159: Model is saved. Elapsed: 19:34:39.92 \n",
      "\n",
      "step 174000: loss = 2.9797005653381348\n",
      "step 175000: loss = 2.460597515106201\n",
      " Epoch 160: Model is saved. Elapsed: 19:42:00.20 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.perf_counter()\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    model = Model(reversed_dict, article_max_len, summary_max_len)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    if 'old_model_checkpoint_path' in globals():\n",
    "        print(\"Continuing from previous trained model:\" , old_model_checkpoint_path , \"...\")\n",
    "        saver.restore(sess, old_model_checkpoint_path )\n",
    "\n",
    "    batches = batch_iter(train_x, train_y, 64, 160)\n",
    "    num_batches_per_epoch = (len(train_x) - 1) // 64 + 1\n",
    "\n",
    "    print(\"\\nIteration starts.\")\n",
    "    print(\"Number of batches per epoch :\", num_batches_per_epoch)\n",
    "    for batch_x, batch_y in batches:\n",
    "        batch_x_len = list(map(lambda x: len([y for y in x if y != 0]), batch_x))\n",
    "        batch_decoder_input = list(map(lambda x: [word_dict[\"<s>\"]] + list(x), batch_y))\n",
    "        batch_decoder_len = list(map(lambda x: len([y for y in x if y != 0]), batch_decoder_input))\n",
    "        batch_decoder_output = list(map(lambda x: list(x) + [word_dict[\"</s>\"]], batch_y))\n",
    "\n",
    "        batch_decoder_input = list(\n",
    "            map(lambda d: d + (summary_max_len - len(d)) * [word_dict[\"<padding>\"]], batch_decoder_input))\n",
    "        batch_decoder_output = list(\n",
    "            map(lambda d: d + (summary_max_len - len(d)) * [word_dict[\"<padding>\"]], batch_decoder_output))\n",
    "\n",
    "        train_feed_dict = {\n",
    "            model.batch_size: len(batch_x),\n",
    "            model.X: batch_x,\n",
    "            model.X_len: batch_x_len,\n",
    "            model.decoder_input: batch_decoder_input,\n",
    "            model.decoder_len: batch_decoder_len,\n",
    "            model.decoder_target: batch_decoder_output\n",
    "        }\n",
    "\n",
    "        _, step, loss = sess.run([model.update, model.global_step, model.loss], feed_dict=train_feed_dict)\n",
    "\n",
    "        if step % 1000 == 0:\n",
    "            print(\"step {0}: loss = {1}\".format(step, loss))\n",
    "\n",
    "        if step % num_batches_per_epoch == 0:\n",
    "            hours, rem = divmod(time.perf_counter() - start, 3600)\n",
    "            minutes, seconds = divmod(rem, 60)\n",
    "            saver.save(sess, \"./saved_model/model.ckpt\", global_step=step)\n",
    "            print(\" Epoch {0}: Model is saved.\".format(step // num_batches_per_epoch),\n",
    "            \"Elapsed: {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds) , \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
